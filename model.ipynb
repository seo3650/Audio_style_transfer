{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "# from data_loader import get_loader\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual Block with instance normalization.\"\"\"\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.main(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator network.\"\"\"\n",
        "    def __init__(self, conv_dim=64, num_speakers=10, repeat_num=6):\n",
        "        super(Generator, self).__init__()\n",
        "        c_dim = num_speakers\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(1+c_dim, conv_dim, kernel_size=(3, 9), padding=(1, 4), bias=False))\n",
        "        layers.append(nn.InstanceNorm2d(conv_dim, affine=True, track_running_stats=True))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # Down-sampling layers.\n",
        "        curr_dim = conv_dim\n",
        "        for i in range(2):\n",
        "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3), bias=False))\n",
        "            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True, track_running_stats=True))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            curr_dim = curr_dim * 2\n",
        "\n",
        "        # Bottleneck layers.\n",
        "        for i in range(repeat_num):\n",
        "            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n",
        "\n",
        "        # Up-sampling layers.\n",
        "        for i in range(2):\n",
        "            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False))\n",
        "            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            curr_dim = curr_dim // 2\n",
        "\n",
        "        layers.append(nn.Conv2d(curr_dim, 1, kernel_size=7, stride=1, padding=3, bias=False))\n",
        "        self.main = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        # Replicate spatially and concatenate domain information.\n",
        "        c = c.view(c.size(0), c.size(1), 1, 1)\n",
        "        c = c.repeat(1, 1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, c], dim=1)\n",
        "        return self.main(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator network with PatchGAN.\"\"\"\n",
        "    def __init__(self, input_size=(36, 256), conv_dim=64, repeat_num=5, num_speakers=10):\n",
        "        super(Discriminator, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(1, conv_dim, kernel_size=4, stride=2, padding=1))\n",
        "        layers.append(nn.LeakyReLU(0.01))\n",
        "\n",
        "        curr_dim = conv_dim\n",
        "        for i in range(1, repeat_num):\n",
        "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1))\n",
        "            layers.append(nn.LeakyReLU(0.01))\n",
        "            curr_dim = curr_dim * 2\n",
        "\n",
        "        kernel_size_0 = int(input_size[0] / np.power(2, repeat_num)) # 1\n",
        "        kernel_size_1 = int(input_size[1] / np.power(2, repeat_num)) # 8\n",
        "        self.main = nn.Sequential(*layers)\n",
        "        self.conv_dis = nn.Conv2d(curr_dim, 1, kernel_size=(kernel_size_0, kernel_size_1), stride=1, padding=0, bias=False) # padding should be 0\n",
        "        self.conv_clf_spks = nn.Conv2d(curr_dim, num_speakers, kernel_size=(kernel_size_0, kernel_size_1), stride=1, padding=0, bias=False)  # for num_speaker\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.main(x)\n",
        "        out_src = self.conv_dis(h)\n",
        "        out_cls_spks = self.conv_clf_spks(h)\n",
        "        return out_src, out_cls_spks.view(out_cls_spks.size(0), out_cls_spks.size(1))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    train_loader = get_loader('/scratch/sxliu/data_exp/VCTK-Corpus-22.05k/mc/train', 16, 'train', num_workers=1)\n",
        "    data_iter = iter(train_loader)\n",
        "    G = Generator().to(device)\n",
        "    D = Discriminator().to(device)\n",
        "    for i in range(10):\n",
        "        mc_real, spk_label_org, acc_label_org, spk_acc_c_org = next(data_iter)\n",
        "        mc_real.unsqueeze_(1) # (B, D, T) -> (B, 1, D, T) for conv2d\n",
        "        mc_real = mc_real.to(device)                         # Input mc.\n",
        "        spk_label_org = spk_label_org.to(device)             # Original spk labels.\n",
        "        acc_label_org = acc_label_org.to(device)             # Original acc labels.\n",
        "        spk_acc_c_org = spk_acc_c_org.to(device)             # Original spk acc conditioning.\n",
        "        mc_fake = G(mc_real, spk_acc_c_org)\n",
        "        print(mc_fake.size())\n",
        "        out_src, out_cls_spks, out_cls_emos = D(mc_fake)\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}